{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size=30\n",
    "\n",
    "height = 28\n",
    "width = 28\n",
    "channels = 1\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 3\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 64\n",
    "n_outputs = 10\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\") # None, 784\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels]) # None, 28, 28, 1\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\") # [None]\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "# conv1 -> None, 28, 28, 32\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "\n",
    "# conv2 -> None, 14, 14, 64\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    # pool3 -> None, 7, 7, 64\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 7 * 7])\n",
    "    #pool3_flat -> None, 64*7*7\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [2]],\n",
       "\n",
       "       [[3],\n",
       "        [4]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myarray = np.array([[1, 2], [3, 4]])\n",
    "myarray.reshape(2, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/fashion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = mnist.train.next_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 1, 5, 5, 7, 1, 6, 5, 6, 2, 7, 7, 0, 8, 6, 3, 7, 5, 9, 5, 8,\n",
       "       1, 6, 5, 5, 1, 3, 3, 0], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = X_batch.reshape((-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6e29817198>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_reshaped[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.9 Test accuracy: 0.863\n",
      "1 Train accuracy: 0.93 Test accuracy: 0.8839\n",
      "2 Train accuracy: 0.88 Test accuracy: 0.8945\n",
      "3 Train accuracy: 0.91 Test accuracy: 0.896\n",
      "4 Train accuracy: 0.93 Test accuracy: 0.9058\n",
      "5 Train accuracy: 0.97 Test accuracy: 0.9032\n",
      "6 Train accuracy: 0.96 Test accuracy: 0.9086\n",
      "7 Train accuracy: 0.96 Test accuracy: 0.9043\n",
      "8 Train accuracy: 0.95 Test accuracy: 0.9143\n",
      "9 Train accuracy: 0.97 Test accuracy: 0.9098\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "\n",
    "        save_path = saver.save(sess, \"model_ckps/my_mnist_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
